{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M6 - WEEK 6 | PROJECT: Kaggle Competition - Predict Traffic Congestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Our task here is to predict traffic congestion based on aggregate measures of  stopping distance and waiting times at intersections in 4 major US cities.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -   process data\n",
    " -  run model\n",
    " - submit predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all useful modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # import pandas\n",
    "import numpy as np # import numpy\n",
    "\n",
    "# encoding and splitting\n",
    "from sklearn import preprocessing # preprocessing for Label and OneHotEncode\n",
    "from sklearn.model_selection import train_test_split #for train test split\n",
    "\n",
    "# models\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.linear_model import Lasso\n",
    "#from sklearn.linear_model import RidgeCV\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "## other necessary models\n",
    "#from sklearn.linear_model import SGDRegressor\n",
    "#from sklearn.ensemble import AdaBoostRegressor\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "## import Gridsearch for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# used metrics\n",
    "from sklearn.metrics import mean_squared_error # import mean squared error as we are suppose to use rmse\n",
    "\n",
    "#silence warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv') # load train\n",
    "test = pd.read_csv('data/test.csv') #load test\n",
    "subdf  = pd.read_csv('data/sample_submission.csv') # load submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a function to process data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataproc(df):\n",
    "    _df = df\n",
    "    \n",
    "    # 'IntersectionId', 'EntryStreetName', 'ExitStreetName', 'Path',   --- removed as latitutde and longitude gives location and heading gives direction\n",
    "    feat_list = ['Latitude', 'Longitude', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'Month', 'City']\n",
    "    num_feat_list = ['Latitude', 'Longitude', 'Hour', 'Weekend', 'Month']\n",
    "    cat_feat_list = ['EntryHeading', 'ExitHeading', 'City']\n",
    "    \n",
    "    \n",
    "    X = _df[feat_list]\n",
    "        \n",
    "    #select cat\n",
    "    X1 = X.select_dtypes(include=[object])\n",
    "\n",
    "    #LabelEncode\n",
    "    # instantiate\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # fit and transform\n",
    "    X2 = X1.apply(le.fit_transform)\n",
    "\n",
    "    #OneHotEncode\n",
    "    # instantiate\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # fit and transform\n",
    "    enc.fit(X2)\n",
    "    X3 = enc.transform(X2).toarray()\n",
    "\n",
    "    X3p = pd.DataFrame(X3, columns = [\"Cat_\"+str(int(i)) for i in range(X3.shape[1])])\n",
    "\n",
    "    Xx = pd.concat([X, X3p], axis=1) # merge new features with old\n",
    "    X = Xx.drop(columns=cat_feat_list, axis=1) # drop unecessary features\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataproc(train) # train processed dataset\n",
    "\n",
    "# list of targets\n",
    "targ_list = ['TotalTimeStopped_p20', 'TotalTimeStopped_p40', 'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80', 'DistanceToFirstStop_p20', 'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50', 'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80']\n",
    "\n",
    "#y = train[targ_list] #target dataset will all targets, non submitted included\n",
    "y = train[[\"TotalTimeStopped_p20\", \"TotalTimeStopped_p50\", \"TotalTimeStopped_p80\", \"DistanceToFirstStop_p20\", \"DistanceToFirstStop_p50\", \"DistanceToFirstStop_p80\"]]\n",
    "stest = dataproc(test) # processed test submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model let's split our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=500000, test_size=5000) #, train_size=10000, test_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list all potentially eligible models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'linear regression': LinearRegression(),\n",
    "    'lasso': Lasso(),\n",
    "    'ridge':  RidgeCV(),\n",
    "    'elasticNet': ElasticNet(),\n",
    "    'random forest': RandomForestRegressor(),\n",
    "    'decision tree':DecisionTreeRegressor(),\n",
    "    'extra-trees': ExtraTreesRegressor(),\n",
    "    'sdg regressor': SGDRegressor(),\n",
    "    'ada boost regressor': AdaBoostRegressor(),\n",
    "    'gradient boosting regressor': GradientBoostingRegressor(),\n",
    "    'extreme boosting regressor': XGBRegressor(**{'objective':'reg:squarederror'})\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark and see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse_matrix = pd.DataFrame(index=y.columns, columns=models.keys())\n",
    "\n",
    "for col in y.columns:\n",
    "        \n",
    "    y_pred = dict()\n",
    "    mse = dict()\n",
    "    \n",
    "    for key, model in models.items():     \n",
    "        model.fit(X_train, y_train[col])                    \n",
    "        y_pred[key] = model.predict(X_test)   \n",
    "        rmse_matrix.at[col,key]= np.sqrt(mean_squared_error(y_test[col], model.predict(X_test)))\n",
    "\n",
    "rmse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in models.keys():\n",
    "    print(rmse_matrix[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "param_grid={'n_estimators': range(400,2001,200), 'max_features': range(5,7)}                            \n",
    "g = RandomizedSearchCV(estimator=model, param_distributions = param_grid, scoring='neg_mean_squared_error', cv=3, n_iter = 100)\n",
    "\n",
    "fit_grid = g.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (fit_grid.best_score_, fit_grid.best_params_))\n",
    "\n",
    "model = ExtraTreesRegressor(**fit_grid.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = y_pred\n",
    "# evaluate predictions\n",
    "mse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"Root Mean Squared Error: %.2f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 7.37859948, 10.27217237, 13.62608743, 15.348207  , 20.70955904,\n",
       "        23.30803593, 24.71918726, 27.26777538, 31.57728386,  7.54235554,\n",
       "         9.54821761, 12.93862764, 15.89907424, 18.94697682, 22.24446352,\n",
       "        25.52884634, 28.82547569, 31.75870236]),\n",
       " 'std_fit_time': array([0.24015818, 0.2815709 , 0.47481275, 0.27010222, 0.29178179,\n",
       "        0.30401208, 0.81898882, 0.22267587, 0.08078393, 1.19410693,\n",
       "        0.24039935, 0.19536236, 0.12448242, 0.29116588, 0.05597833,\n",
       "        0.25454878, 0.51465075, 0.34825985]),\n",
       " 'mean_score_time': array([0.35075315, 0.49085514, 0.69047173, 0.75797296, 1.03090914,\n",
       "        1.10536949, 1.29155024, 1.3682162 , 1.55668481, 0.33510335,\n",
       "        0.46741478, 0.61802189, 0.76196257, 0.9617552 , 1.06450407,\n",
       "        1.25065748, 1.3457338 , 1.46541254]),\n",
       " 'std_score_time': array([0.0155976 , 0.05834535, 0.1057241 , 0.01785973, 0.02558856,\n",
       "        0.02200082, 0.10514374, 0.025956  , 0.04191156, 0.02355852,\n",
       "        0.00893104, 0.01811103, 0.01253761, 0.06710321, 0.02029417,\n",
       "        0.02684605, 0.01668995, 0.00654599]),\n",
       " 'param_n_estimators': masked_array(data=[400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 400,\n",
       "                    600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 400, 'max_features': 5},\n",
       "  {'n_estimators': 600, 'max_features': 5},\n",
       "  {'n_estimators': 800, 'max_features': 5},\n",
       "  {'n_estimators': 1000, 'max_features': 5},\n",
       "  {'n_estimators': 1200, 'max_features': 5},\n",
       "  {'n_estimators': 1400, 'max_features': 5},\n",
       "  {'n_estimators': 1600, 'max_features': 5},\n",
       "  {'n_estimators': 1800, 'max_features': 5},\n",
       "  {'n_estimators': 2000, 'max_features': 5},\n",
       "  {'n_estimators': 400, 'max_features': 6},\n",
       "  {'n_estimators': 600, 'max_features': 6},\n",
       "  {'n_estimators': 800, 'max_features': 6},\n",
       "  {'n_estimators': 1000, 'max_features': 6},\n",
       "  {'n_estimators': 1200, 'max_features': 6},\n",
       "  {'n_estimators': 1400, 'max_features': 6},\n",
       "  {'n_estimators': 1600, 'max_features': 6},\n",
       "  {'n_estimators': 1800, 'max_features': 6},\n",
       "  {'n_estimators': 2000, 'max_features': 6}],\n",
       " 'split0_test_score': array([-4917.91554286, -4908.49758966, -4938.16866741, -4911.34454892,\n",
       "        -4925.58603448, -4932.49411265, -4930.99869832, -4919.57115638,\n",
       "        -4925.79922414, -4938.92230874, -4939.18504253, -4923.15739036,\n",
       "        -4933.68764178, -4941.27282543, -4915.535041  , -4935.46162306,\n",
       "        -4928.40311671, -4929.05595164]),\n",
       " 'split1_test_score': array([-4787.49046746, -4811.9666884 , -4800.58574407, -4807.48980011,\n",
       "        -4800.18330356, -4811.12705943, -4793.13584273, -4795.05894843,\n",
       "        -4795.08325431, -4788.34842197, -4805.27541198, -4801.37115308,\n",
       "        -4800.66076434, -4788.25564061, -4789.53884041, -4808.38446196,\n",
       "        -4794.63371682, -4800.89910623]),\n",
       " 'split2_test_score': array([-4641.60333631, -4646.12573282, -4661.54266703, -4656.63368976,\n",
       "        -4659.12248808, -4655.13205963, -4644.7583177 , -4650.78408432,\n",
       "        -4657.24524446, -4672.3365344 , -4640.40205596, -4650.37517812,\n",
       "        -4649.59086683, -4653.63810431, -4638.84966984, -4639.65096363,\n",
       "        -4649.04807456, -4641.53090987]),\n",
       " 'mean_test_score': array([-4782.35000678, -4788.87530038, -4800.11283313, -4791.83463178,\n",
       "        -4794.97700425, -4799.59770154, -4789.64508969, -4788.48450635,\n",
       "        -4792.72254997, -4799.88299369, -4794.96859324, -4791.64772614,\n",
       "        -4794.66032844, -4794.40354518, -4781.32127314, -4794.51311248,\n",
       "        -4790.70874018, -4790.50917864]),\n",
       " 'std_test_score': array([112.86534182, 108.35268673, 112.93540875, 104.57533712,\n",
       "        108.84826944, 113.52846315, 116.88612758, 109.83301812,\n",
       "        109.6521475 , 109.14104487, 122.1981849 , 111.57766107,\n",
       "        116.0624909 , 117.50974484, 113.10848442, 121.16481605,\n",
       "        114.08282749, 117.61418886]),\n",
       " 'rank_test_score': array([ 2,  4, 18,  9, 15, 16,  5,  3, 10, 17, 14,  8, 13, 11,  1, 12,  7,\n",
       "         6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = ExtraTreesRegressor()\n",
    "param_grid={\n",
    "        #'n_estimators': range(50,126,25),\n",
    "        'max_features': range(0,25,3),\n",
    "        #'min_samples_leaf': range(20,50,5),\n",
    "        #'min_samples_split': range(15,36,5),\n",
    "    }                            \n",
    "g = GridSearchCV(estimator=model, param_grid = param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "fit_grid = g.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (fit_grid.best_score_, fit_grid.best_params_))\n",
    "\n",
    "for test_mean, train_mean, param in zip(\n",
    "        fit_grid.cv_results_['mean_test_score'],\n",
    "        fit_grid.cv_results_['mean_train_score'],\n",
    "        fit_grid.cv_results_['params']):\n",
    "    print(\"Train: %f // Test : %f with: %r\" % (train_mean, test_mean, param))\n",
    "    \n",
    "#model = ExtraTreesRegressor(**fit_grid.best_params_)\n",
    "\n",
    "#model.fit(train, y_train)\n",
    "\n",
    "#df_sub = pd.DataFrame({'ID': id_test, 'y': model.predict(test)})\n",
    "#df_sub.to_csv('mercedes-submission.csv', index=False)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = y_pred\n",
    "# evaluate predictions\n",
    "mse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"Root Mean Squared Error: %.2f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use our model to predict based on submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = model.predict(stest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's submit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def subm(y_pred):\n",
    "    tpre = pd.DataFrame(y_pred, columns=targ_list)\n",
    "    dpred = pd.DataFrame({\"0\": tpre[\"TotalTimeStopped_p20\"], \"1\": tpre[\"TotalTimeStopped_p50\"], \"2\": tpre[\"TotalTimeStopped_p80\"], \"3\": tpre[\"DistanceToFirstStop_p20\"], \"4\": tpre[\"DistanceToFirstStop_p50\"], \"5\": tpre[\"DistanceToFirstStop_p80\"]})\n",
    "    subdf['Target'] = dpred.stack().values\n",
    "    subdf.to_csv('meosub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subdf  = pd.read_csv('data/sample_submission.csv') # load submission file\n",
    "subm(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in(range(200,2000,200)):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
