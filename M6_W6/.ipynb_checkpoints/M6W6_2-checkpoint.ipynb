{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M6W6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing # preprocessing for Label and OneHotEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# 'IntersectionId', 'EntryStreetName', 'ExitStreetName', 'Path',   --- removed as latitutde and longitude gives location and heading gives direction\n",
    "feat_list = ['Latitude', 'Longitude', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'Month', 'City']\n",
    "num_feat_list = ['Latitude', 'Longitude', 'Hour', 'Weekend', 'Month']\n",
    "cat_feat_list = ['EntryHeading', 'ExitHeading', 'City']\n",
    "targ_list = ['TotalTimeStopped_p20', 'TotalTimeStopped_p40', 'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80', 'DistanceToFirstStop_p20', 'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50', 'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80']\n",
    "\n",
    "X = train[feat_list]\n",
    "y = train[targ_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romeo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#select cat\n",
    "X1 = X.select_dtypes(include=[object])\n",
    "\n",
    "#LabelEncode\n",
    "# instantiate\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "# fit and transform\n",
    "X2 = X1.apply(le.fit_transform)\n",
    "\n",
    "#OneHotEncode\n",
    "# instantiate\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# fit and transform\n",
    "enc.fit(X2)\n",
    "X3 = enc.transform(X2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Month</th>\n",
       "      <th>Cat_0</th>\n",
       "      <th>Cat_1</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Cat_3</th>\n",
       "      <th>Cat_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_10</th>\n",
       "      <th>Cat_11</th>\n",
       "      <th>Cat_12</th>\n",
       "      <th>Cat_13</th>\n",
       "      <th>Cat_14</th>\n",
       "      <th>Cat_15</th>\n",
       "      <th>Cat_16</th>\n",
       "      <th>Cat_17</th>\n",
       "      <th>Cat_18</th>\n",
       "      <th>Cat_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.79166</td>\n",
       "      <td>-84.43003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.79166</td>\n",
       "      <td>-84.43003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.79166</td>\n",
       "      <td>-84.43003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.79166</td>\n",
       "      <td>-84.43003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.79166</td>\n",
       "      <td>-84.43003</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude  Hour  Weekend  Month  Cat_0  Cat_1  Cat_2  Cat_3  \\\n",
       "0  33.79166  -84.43003     0        0      6    0.0    0.0    0.0    1.0   \n",
       "1  33.79166  -84.43003     0        0      6    0.0    0.0    0.0    0.0   \n",
       "2  33.79166  -84.43003     1        0      6    0.0    0.0    0.0    1.0   \n",
       "3  33.79166  -84.43003     1        0      6    0.0    0.0    0.0    0.0   \n",
       "4  33.79166  -84.43003     2        0      6    0.0    0.0    0.0    1.0   \n",
       "\n",
       "   Cat_4  ...  Cat_10  Cat_11  Cat_12  Cat_13  Cat_14  Cat_15  Cat_16  Cat_17  \\\n",
       "0    0.0  ...     0.0     1.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1    0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "2    0.0  ...     0.0     1.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "3    0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "4    0.0  ...     0.0     1.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "   Cat_18  Cat_19  \n",
       "0     0.0     0.0  \n",
       "1     0.0     0.0  \n",
       "2     0.0     0.0  \n",
       "3     0.0     0.0  \n",
       "4     0.0     0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3p = pd.DataFrame(X3, columns = [\"Cat_\"+str(int(i)) for i in range(X3.shape[1])])\n",
    "\n",
    "Xx = pd.concat([X, X3p], axis=1) # merge new features with old\n",
    "X = Xx.drop(columns=cat_feat_list, axis=1) # drop uneccesarry features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataproc(df):\n",
    "    _df = df\n",
    "    \n",
    "    # 'IntersectionId', 'EntryStreetName', 'ExitStreetName', 'Path',   --- removed as latitutde and longitude gives location and heading gives direction\n",
    "    feat_list = ['Latitude', 'Longitude', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'Month', 'City']\n",
    "    num_feat_list = ['Latitude', 'Longitude', 'Hour', 'Weekend', 'Month']\n",
    "    cat_feat_list = ['EntryHeading', 'ExitHeading', 'City']\n",
    "    targ_list = ['TotalTimeStopped_p20', 'TotalTimeStopped_p40', 'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80', 'DistanceToFirstStop_p20', 'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50', 'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80']\n",
    "    \n",
    "    X = _df[feat_list]\n",
    "        \n",
    "    #select cat\n",
    "    X1 = X.select_dtypes(include=[object])\n",
    "\n",
    "    #LabelEncode\n",
    "    # instantiate\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    # fit and transform\n",
    "    X2 = X1.apply(le.fit_transform)\n",
    "\n",
    "    #OneHotEncode\n",
    "    # instantiate\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # fit and transform\n",
    "    enc.fit(X2)\n",
    "    X3 = enc.transform(X2).toarray()\n",
    "\n",
    "    X3p = pd.DataFrame(X3, columns = [\"Cat_\"+str(int(i)) for i in range(X3.shape[1])])\n",
    "\n",
    "    Xx = pd.concat([X, X3p], axis=1) # merge new features with old\n",
    "    X = Xx.drop(columns=cat_feat_list, axis=1) # drop unecessary features\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romeo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "AX = dataproc(train)\n",
    "Ay = train[targ_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "## multioutput necessary models\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# used metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=100000, test_size=5000) #, train_size=100000, test_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'linear regression': LinearRegression(),\n",
    "    'lasso': Lasso(),\n",
    "    'ridge':  RidgeCV(),\n",
    "    'elasticNet': ElasticNet(),\n",
    "    'random forest': RandomForestRegressor(),\n",
    "    'decision tree':DecisionTreeRegressor(),\n",
    "    'extra-trees': ExtraTreesRegressor(),\n",
    "    'sdg regressor': MultiOutputRegressor(SGDRegressor()),\n",
    "    'ada boost regressor': MultiOutputRegressor(AdaBoostRegressor()),\n",
    "    'gradient boosting regressor': MultiOutputRegressor(GradientBoostingRegressor()),\n",
    "    'extreme boosting regressor': MultiOutputRegressor(XGBRegressor(**{'objective':'reg:squarederror'}))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 Create an empty dictionary to collect prediction values\n",
    "y_pred = dict()\n",
    "mse = dict()\n",
    "\n",
    "for key, model in models.items():     \n",
    "    model.fit(X_train, y_train)                    \n",
    "    y_pred[key] = model.predict(X_test)   \n",
    "    mse[key] = mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 63.71\n"
     ]
    }
   ],
   "source": [
    "# fit model to training data\n",
    "model = MultiOutputRegressor(XGBRegressor(**{'objective':'reg:squarederror'}))\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = y_pred\n",
    "# evaluate predictions\n",
    "mse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"Root Mean Squared Error: %.2f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 49.41\n"
     ]
    }
   ],
   "source": [
    "# with gridsearch specs\n",
    "model = MultiOutputRegressor(XGBRegressor(learning_rate= 0.3, max_depth= 6, **{'objective':'reg:squarederror'}))\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = y_pred\n",
    "# evaluate predictions\n",
    "mse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"Root Mean Squared Error: %.2f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 107.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 609.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -3314.173388 using {'estimator__learning_rate': 0.3, 'estimator__max_depth': 6, 'estimator__n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(XGBRegressor(**{'objective':'reg:squarederror'}))\n",
    "#fitparams = {'eval_set ': [(X_train, y_train), (X_test, y_test)], 'eval_metric' : \"rmse\"}\n",
    "#model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n",
    "gridparams = {'estimator__learning_rate': [0.0001, 0.001, 0.05, 0.1, 0.2, 0.3], 'estimator__n_jobs' : [-1], 'estimator__max_depth': [4,5,6]}\n",
    "\n",
    "g = GridSearchCV(model, gridparams, verbose=1, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "r =g.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (r.best_score_, r.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3260.267681385653"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, r.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            importance_type='gain',\n",
       "                                            learning_rate=0.3, max_delta_step=0,\n",
       "                                            max_depth=6, min_child_weight=1,\n",
       "                                            missing=None, n_estimators=100,\n",
       "                                            n_jobs=-1, nthread=None,\n",
       "                                            objective='reg:squarederror',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            seed=None, silent=None, subsample=1,\n",
       "                                            verbosity=1),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Latitude', 'Longitude', 'Hour', 'Weekend', 'Month'], dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
